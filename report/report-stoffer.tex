\documentclass[a4paper,oneside,article,11pt]{memoir}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}

\newtheorem*{toprove}{At bevise}
\newtheorem{thrm}{Theorem}
\newtheorem{lemma}{Lemma}

% This font looks so good.
\usepackage[sc]{mathpazo}

% Typesetting pseudo-code
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
% Code comments like [CLRS]
\renewcommand{\algorithmiccomment}[1]{\makebox[5cm][l]{$\triangleright$ \textit{#1}}}
\usepackage{framed,graphicx,xcolor}
\usepackage{listings}

\usepackage[font={small,it}]{caption}

% Relative references
\usepackage{varioref}

\usepackage{tikz}

\bibliographystyle{plain}

\title{Dynamic Algorithms \\ Dynamic Transitive Closure }
\author{Peter Gabrielsen 20114179 \\
Christoffer Hansen 20114637}
\newcounter{qcounter}
\begin{document}

\maketitle

\chapter{Introduction}
In this project we look at the dynamic transitive closure problem of a directed unweighted graph $G$.

\begin{itemize}
\item{\texttt{init($n$)}: $G$ becomes the empty directed graph with vertices $\left\lbrace 0,\dots, n-1\right\rbrace$ and no edges.}
\item{\texttt{insert($i,j$)}: Inserts an edge from $i$ to $j$ into $G$ (if it is not already contained in $G$).}
\item{\texttt{delete($i,j$)}: Deletes an edge from $i$ to $j$ from $G$ (if it is contained in $G$).}
\item{\texttt{transitiveClosure?}: Returns the total number of edges in the transitive closure graphs.}
\end{itemize}

We are going to implement two dynamic algorithms for this problem. The first, presented in section \ref{chap:fw}, is a trivial solution based on the Floyd-Warshall algorithm for computing all pairs shortest paths. The next solution, presented in \ref{chap:sankowski}, is based on Sankowskis randomized reduction to dynamic matrix adjoint combined with the use of the Sherman-Morrison formula.

The second solution requires us to do arithmetic modulo a prime $p$. We are thus going to describe algorithms for this in time $O(log^2 p)$ in section \ref{chap:prime}.

Finally we are going to experimentally test both algorithms and compare their running time on different inputs interesting to this problem.


\chapter{Floyd-Warshall}
\label{chap:fw}

Floyd-Warshalls 

%algorithm
\begin{algorithm}[H]
\caption{\textsc{Floyd-Warshall Transitive Closure}(Graph $G$)}
\label{alg:fw}
\begin{algorithmic}[1]
\FOR{$k \leftarrow 1 $ to $n$}
	\FOR{$i \leftarrow 1 $ to $n$}
		\FOR{$j \leftarrow 1 $ to $n$}
			\STATE{$G_{ij} = G_{ij} \vee (G_{ik} \wedge G_{kj})$}
		\ENDFOR
	\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

\chapter{Truly dynamic algorithm}
\label{chap:sankowski}

The truly dynamic algorithm we will present is due to Sankowskis randomized reduction to dynamic matrix adjoint~\cite{Reif1997347} with use of the Sherman-Morrison formula~\cite{lecnotes}.

\paragraph{Sankowski} presents the following theorem in \cite{Reif1997347}, which is the main idea of our proposed algorithm.

\begin{thrm}

\label{thrm:sankowski-path}
Let $A$ be the adjacency matrix of a graph $G$. There exists a path in $G$ from $i$ to $j$ \textit{iff} $adj(I-A)_{ij}$ as polynomial of entries of $A$ is symbolically not equal to zero.
\end{thrm}

Assuming $I-A$ is non-singular it trivially follows that $det(I-A) \not = 0$. From the relation $(I-A)^{-1} = \frac{adj(I-A)}{det(I-A)}$ it follows that $(I-A)^{-1}$ could simply be considered as a scaling of $adj(I-A)$ by a scalar corresponding to $\frac{1}{det(I-A)}$. In other words non-zero entries of $adj(I-A)$ is preserved when dividing with $det(I-A)$. We conclude there is a homomorphic relation between Theorem \ref{thrm:sankowski-path} and $(I-A)^{-1}$. %TODO Are we sure we can call this a homomorphic relation?

\paragraph{Sherman-Morrison formula}

Assume $A$ is an invertible square matrix of size $nxn$ and $u$, $v$ are column vectors of size $nx1$. For now we will assume that $1 + v^T A^{-1} u \not = 0$.

From the Sherman-Morrison formula,

\begin{equation} \label{eq:ShermanMorrison}
(A+uv^T)^{-1} = A^{-1} - \dfrac{A^{-1}uv^TA^{-1}}{1 + v^T A^{-1} u}
\end{equation}

one may see that we are provided with a numerical cheap way of computing the inverse of $A + uv^T$ under the invariant that we know $A^{-1}$. It is clear that $uv^T$ can be considered as a rank-one update of the matrix $A$.

%TODO Should we show that SM can be computed effeciently?

\paragraph{Putting it all together}
The idea of the algorithm is to combine Sankowskis reduction to dynamic matrix adjoint combined with the Sherman-Morrison formula.

Unfortunately we can not rely on a polynomial of degree $n$ as it could take exponential time to evaluate. In order to come around this issue we pick a prime $p$ and for each variable (i.e. non-zero entry of $A$) we substitute with a uniformly random $r \in \mathbb{Z}_{p} := \mathbb{Z} / p\mathbb{Z}$.


\begin{itemize}
\item{\texttt{init($n$)}: Set $A^{-1}$ = $I_n$. Note that $I_n$ is equal to $(I_n)^{-1}$. Also  initialize a matrix $B^{nxn}$ taking uniformly random values from $\mathbb{Z}_p$ in all entries.}
\item{\texttt{insert($i,j$)}: Let $u = e_i$ be the unit column vector of length $n$ with 1 in entry $i$. Let $v$ be the column vector of length n with all-zeroes expect from entry $j$ that takes it value from $B_{ij}$.
Use the Sherman-Morrison formula presented in Equation~\ref{eq:ShermanMorrison} to compute the inverse $A^{-1}$.}
\item{\texttt{delete($i,j$)}: As \texttt{delete($i,j$)} could simply be viewed as the inverse permutation of A with respect to \texttt{insert($i,j$)}, we change the signs in Sherman-Morrison as follows

$$(A+uv^T)^{-1} = A^{-1} + \dfrac{A^{-1}uv^TA^{-1}}{1 - v^T A^{-1} u}$$}

Assuming $u$, $v$ on the same form as in \texttt{insert($i,j$)}, we are ensured an inverse permutation of A.

\item{\texttt{transitiveClosure?}: From Theorem~\ref{thrm:sankowski-path} it follows that we just have to report all non-zero entries of $A^{-1}$.}
\end{itemize}

\paragraph{Complexity analysis}

By relying on the substitution of polynomial variables into random numbers, we introduce the unfortunate event of falsely evaluating to zero. The error of this happening is upper bounded by Zippel and Schwartz in Lemma~\ref{lma:zippelSchwarz}.

\begin{lemma}
\label{lma:zippelSchwarz}
If $p(x_1$,...,$x_m)$ is a non-zero polynomial of degree $d$ with coefficients in a field and $S$ is a subset of the field, then the probability that $p$ evaluates to 0 on a random element $(s_1$,$s_2$...,$s_m) \in S^m$ is at most $d/\mid S \mid$. We call this event false zero.
\end{lemma}

As $\mid d \mid \leq n$ we we will get a false zero with probability less than $\frac{n}{p}$. By setting $p > n^2$ we get the desired error probability of $\frac{1}{n}$.

\begin{itemize}
\item{\texttt{init($n$)}: Computing the identity matrix of size n can trivially be done in $\mathcal{O}(n^2)$ time and space. Also compute the random matrix $B^{nxn}$ that takes random values from $\mathbb{Z}_p$. It is assumed that we can choose a uniformly random k-bit number in time $\mathcal{O}(k)$. Thus it takes $\mathcal{O}(n^2 log p)$ to initialize $B$. Note that we can use lazy initialization to get a $\mathcal{O}(1)$ running time.}
\item{\texttt{insert($i,j$)}: The Sherman-Morrison takes $\mathcal{O}(n^2)$ to evaluate. We assume arithmetic operations can be done in $O(\log^2 p)$ per operation in $\mathbb{Z}_p$. This gives a total running time of $\mathcal{O}(n^2 \log^2 p)$.}
\item{\texttt{delete($i,j$)}: Same analysis as insert(i,j) gives $\mathcal{O}(n^2 \log^2 p)$.}
\item{\texttt{transitiveClosure?}: We run through the entire matrix $A^{-1}$ yielding a $\mathcal{O}(n^2)$ traversal to report.}
\end{itemize}

All results are repeated in~Figure~\ref{fig:truly-comp}.

\begin{figure}[h]
\center{
\begin{tabular}{|c|c|c|}
\hline
Operation & Normal initialize & Lazy initialize \\\hline
\texttt{init} & $\mathcal{O}(n^2 \log p)$ & $\mathcal{O}(1)$ \\
\texttt{insert} & $\mathcal{O}(n^2 \log^2 p)$ & $\mathcal{O}(n^2 \log^2 p)$ \\
\texttt{delete} & $\mathcal{O}(n^2 \log^2 p)$ & $\mathcal{O}(n^2 \log^2 p)$ \\
\texttt{transitiveClosure?} & $\mathcal{O}(n^2)$ & $\mathcal{O}(n^2)$ \\\hline
\end{tabular}
}
\caption{Complexities of each operation for the truly dynamic solution.}
\label{fig:truly-comp}
\end{figure}

\chapter{Implementation}
\label{impl}

Using Lemma~\ref{lma:zippelSchwarz} (Zippel and Schwarz) we showed that for $d = n$ we get a false zero probability less than $\frac{n}{p}$. From this it follows that for any $p > n^2$ we can guarantee an error probability less than $\frac{1}{n}$. Setting $p = 2^{31}-1$ we can guarantee an error probability of $\frac{1}{n}$ for all $n \leq \sqrt{p} < \sqrt{p+1} = \sqrt{2^{31}} = 2^{15.5}$.

\bibliography{references}

\end{document}


